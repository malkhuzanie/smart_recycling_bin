# python-services/services/cnn_service.py (Final Integrated Version)

import asyncio
import copy
import cv2
import numpy as np
from typing import Dict, Optional, Tuple
from datetime import datetime
import logging
import json
import sys
import os
from pathlib import Path
import base64
from PIL import Image
import io

from tensorflow.keras.models import load_model

from tensorflow.keras.applications.resnet50 import preprocess_input

# --- 1. Import your new YOLO service and the Hub Client ---
from .yolo_service import detect_relevant_objects, model as yolo_model
from .hub_client import SignalRHubClient

# --- 2. Add src to path to import expert system components ---
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

try:
    from smart_bin.core.knowledge_engine import SmartBinKnowledgeEngine
    from smart_bin.core.facts import WasteFact
except ImportError as e:
    logging.warning(f"Could not import expert system components: {e}")
    SmartBinKnowledgeEngine = None
    WasteFact = None

class CNNService:
    """Orchestrates the visual detection (YOLO) and expert system logic."""
    
    def __init__(self, backend_hub_url: str):

        self.logger = logging.getLogger("CNNService")

        self.model = yolo_model

         # --- START of REVISED CODE for LOCAL PATH ---
        self.custom_model = None # Initialize as None
        
        # Construct the path to the model file relative to this script's location
        # Path(__file__) is the path to cnn_service.py
        # .parent.parent gives us the 'python-services' directory
        # .parent again gives us the project root
        project_root = Path(__file__).parent.parent.parent
        custom_model_path = project_root / "models" / "trash_classifier_v3_93_accuracy_4mp.keras"

        try:
            # os.path.exists() can work directly with Path objects
            if os.path.exists(custom_model_path):
                self.custom_model = load_model(custom_model_path)
                self.logger.info(f"Successfully loaded custom classifier from {custom_model_path}")
            else:
                self.logger.error(f"Custom classifier file not found at {custom_model_path}. Fallback will be disabled.")
        except Exception as e:
            self.logger.error(f"Error loading custom classifier: {e}")
        # --- END of REVISED CODE for LOCAL PATH ---

        self.camera = None
        self.hub_client = SignalRHubClient(backend_hub_url, "ClassificationHub")
        
        self.expert_system = SmartBinKnowledgeEngine() if SmartBinKnowledgeEngine else None
        
        # Image capture configuration
        self.image_quality = int(os.getenv('IMAGE_QUALITY', '85'))
        self.max_image_width = int(os.getenv('MAX_IMAGE_WIDTH', '800'))
        self.max_image_height = int(os.getenv('MAX_IMAGE_HEIGHT', '600'))
        self.capture_format = os.getenv('IMAGE_FORMAT', 'JPEG')
        
        # Service integration & state
        self.arduino_service = None # This will be injected by the orchestrator
        self.processing_queue = asyncio.Queue()
        self.is_processing = False
        
    async def start_service(self):
        """Starts the CNN service's main loops."""
        self.logger.info("ðŸš€ Starting CNN Service with YOLOv8 integration...")
        
        try:
            if not self.model:
                self.logger.error("YOLOv8 model failed to load. Aborting service start.")
                return

            if not await self.hub_client.connect():
                self.logger.error("Failed to connect to backend hub")
                return
                
            await self.hub_client.send_message("JoinClassificationGroup", "")
            await self.initialize_camera()
            
            # This worker will process requests put into the queue
            asyncio.create_task(self.classification_worker())
            # This worker sends periodic health updates
            asyncio.create_task(self.heartbeat_worker())
            
        except Exception as e:
            self.logger.error(f"Failed to start CNN service: {e}", exc_info=True)
            raise

    def set_arduino_service(self, arduino_service):
        """Allows the orchestrator to inject the Arduino service instance."""
        self.arduino_service = arduino_service
        self.logger.info("âœ… Arduino service successfully integrated into CNNService.")

    async def trigger_classification(self, item_data: Dict):
        """Public method called by other services (like ArduinoService) to start a job."""
        if self.is_processing:
            self.logger.warning(f"Already processing an item. Ignoring trigger for {item_data.get('detection_id')}")
            return
        await self.processing_queue.put(item_data)

    async def classification_worker(self):
        """Worker that processes items from the queue, one by one."""
        while True:
            item_data = await self.processing_queue.get()
            self.is_processing = True
            self.logger.info(f"ðŸ”„ Starting classification for {item_data.get('detection_id')}")
            
            result = await self.run_complete_pipeline_with_image(item_data)
            
            if result:
                await self.send_classification_result_with_image(result)
            else:
                self.logger.error(f" Classification pipeline failed for {item_data.get('detection_id')}")
            
            self.is_processing = False
            self.processing_queue.task_done()

    async def run_complete_pipeline_with_image(self, item_data: Dict) -> Optional[Dict]:
        """The main pipeline for processing a single item."""
        detection_id = item_data.get("detection_id", f"item_{int(datetime.now().timestamp())}")
        start_time = datetime.now()
        
        try:
            # Step 1: Get data from all sources
            image_array, image_data = await self.capture_and_encode_image()
            if image_array is None: return None
            
            sensor_data = await self.get_sensor_data()
            yolo_result = self.run_yolo_detection(image_array) # This is now a synchronous call
            
            # Step 2: Get final decision from Expert System
            expert_result = self.run_expert_system_integration(yolo_result, sensor_data)
            
            if expert_result.get("final_classification") == "unknown" and self.custom_model is not None:
                self.logger.warning("Primary pipeline resulted in 'unknown'. Activating fallback classifier.")
                
                try:
                    # 1. Resize the original image
                    resized_image = cv2.resize(image_array, (384, 384))
                    
                    # 2. Add the 'batch' dimension
                    img_array_expanded = np.expand_dims(resized_image, axis=0)
                    
                    # 3. Apply the official ResNet50 preprocessing
                    preprocessed_image = preprocess_input(img_array_expanded)
                    
                    # 4. Predict using your custom model
                    custom_predictions = self.custom_model.predict(preprocessed_image)
                    
                    # 5. Interpret the result
                    class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic']
                    predicted_index = np.argmax(custom_predictions[0])
                    confidence = float(np.max(custom_predictions[0]))
                    predicted_class = class_names[predicted_index]

                    # 6. Overwrite the expert_result
                    self.logger.info(f"Fallback classifier predicted: '{predicted_class}' with confidence {confidence:.2f}")
                    expert_result = {
                        "final_classification": predicted_class,
                        "confidence": confidence,
                        "disposal_location": self.get_disposal_location(predicted_class),
                        "reasoning": f"object detected visually."
                    }
                except Exception as e:
                    self.logger.error(f"Error during fallback classification: {e}")

            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # Step 3: Compile the full result to send to backend
            complete_result = {
                "detection_id": detection_id,
                "timestamp": item_data.get("timestamp", datetime.now().isoformat()),
                "processing_time_ms": processing_time,
                "image_data": image_data,
                "cnn_prediction": yolo_result,
                "sensor_data": sensor_data,
                "expert_system_result": expert_result,
                "processing_metadata": { "pipeline_version": "yolo_v1.0" }
            }
            return complete_result
            
        except Exception as e:
            self.logger.error(f"Error in complete pipeline: {e}", exc_info=True)
            return None

    def run_yolo_detection(self, image: np.ndarray) -> Dict:
        """Runs YOLOv8 and returns the best detection."""
        try:
            detections, _ = detect_relevant_objects(image)
            
            if not detections:
                return {"predicted_class": "unknown", "confidence": 0.0, "stage": 1}

            best_detection = max(detections, key=lambda d: d['confidence'])
            self.logger.info(f"YOLOv8 detected: {best_detection['label']}@{best_detection['confidence']:.2f}")
            return {"predicted_class": best_detection['label'], "confidence": best_detection['confidence'], "stage": 1}
        except Exception as e:
            self.logger.error(f"Error during YOLOv8 detection: {e}", exc_info=True)
            return {"predicted_class": "error", "confidence": 0.0, "stage": 1}

    def run_expert_system_integration(self, yolo_result: Dict, sensor_data: Dict) -> Dict:
        """Packages data, runs the expert system, and returns the final decision."""
        if not self.expert_system:
            return self.create_fallback_result(yolo_result)
        
        try:
            # Create the WasteFact using all available data
            waste_fact = WasteFact(
                cv_label=yolo_result.get("predicted_class"),
                cv_confidence=yolo_result.get("confidence"),
                weight_grams=sensor_data.get("weight_grams"),
                is_metal=sensor_data.get("is_metal"),
                humidity_percent=sensor_data.get("humidity_percent"),
                ir_transparency=sensor_data.get("ir_transparency"),
                is_moist=sensor_data.get("is_moist"),
                is_transparent=sensor_data.get("is_transparent")
            )
            
            self.expert_system.reset()
            self.expert_system.declare(waste_fact)
            self.expert_system.run()
            
            decision = self.expert_system.get_final_decision()
            
            if not decision.final_classification:
                return self.create_fallback_result(yolo_result)

            final_class = decision.final_classification
            return {
                "final_classification": final_class.category.value,
                "confidence": final_class.confidence,
                "disposal_location": final_class.disposal_location,
                "reasoning": final_class.reasoning,
            }
        except Exception as e:
            self.logger.error(f"Error in expert system integration: {e}", exc_info=True)
            return self.create_fallback_result(yolo_result)

    def create_fallback_result(self, yolo_result: Dict) -> Dict:
        """Creates a fallback result if the expert system fails."""
        yolo_class = yolo_result.get("predicted_class", "unknown")
        return {
            "final_classification": "unknown",
            "confidence": yolo_result.get("confidence", 0.0),
            "disposal_location": "Manual Inspection Bin",
            "reasoning": f"Fallback: Expert system failed. YOLO saw '{yolo_class}'.",
        }

    async def get_sensor_data(self) -> Dict:
        """Gets sensor data from Arduino service or provides mock data if unavailable."""
        if self.arduino_service and self.arduino_service.is_connected:
            sensor_data = await self.arduino_service.read_sensors()
            if sensor_data:
                return sensor_data
        
        # Fallback to mock data if service unavailable or read fails
        self.logger.warning("Using mock sensor data.")
        import random
        return { "weight_grams": random.uniform(5, 500), "is_metal": random.choice([True, False]), "humidity_percent": random.uniform(20, 80), "ir_transparency": random.uniform(0.1, 0.9), "is_moist": random.choice([True, False]), "is_transparent": random.choice([True, False]) }

    # --- Utility and Helper Methods ---

    async def capture_and_encode_image(self) -> Tuple[Optional[np.ndarray], Optional[Dict]]:
        """Captures an image and returns both the raw array and encoded data dict."""
        try:
            image_array = await self.capture_image()
            if image_array is None: return None, None
            
            image_for_encoding = image_array.copy()
            height, width = image_for_encoding.shape[:2]
            
            if width > self.max_image_width or height > self.max_image_height:
                ratio = min(self.max_image_width / width, self.max_image_height / height)
                new_size = (int(width * ratio), int(height * ratio))
                image_for_encoding = cv2.resize(image_for_encoding, new_size)
            
            image_rgb = cv2.cvtColor(image_for_encoding, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image_rgb)
            
            buffer = io.BytesIO()
            pil_image.save(buffer, format=self.capture_format, quality=self.image_quality)
            image_bytes = buffer.getvalue()
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            
            final_height, final_width = image_for_encoding.shape[:2]
            image_data = {
                "image_base64": image_base64, "format": self.capture_format.lower(),
                "dimensions": f"{final_width}x{final_height}", "size_bytes": len(image_bytes),
                "capture_timestamp": datetime.now().isoformat(),
            }
            return image_array, image_data
        except Exception as e:
            self.logger.error(f"Error capturing and encoding image: {e}", exc_info=True)
            return None, None

    async def capture_image(self) -> Optional[np.ndarray]:
        """Captures a single frame from the camera or returns a mock image."""
        if self.camera and self.camera.isOpened():
            ret, frame = self.camera.read()
            if ret:
                return frame
            self.logger.error("Failed to capture frame from camera")
        
        mock_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        cv2.putText(mock_image, 'MOCK IMAGE', (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 5)
        self.logger.info("ðŸ“· Using mock image (camera not available or failed)")
        return mock_image

    async def send_classification_result_with_image(self, result: Dict):
        """Sends the complete, final result to the C# backend via SignalR."""
        try:
            log_result = copy.deepcopy(result)
            if log_result.get("image_data"):
                log_result["image_data"]["image_base64"] = f"<base64 data of {log_result['image_data']['size_bytes']} bytes>"
            
            self.logger.info(f" Sending final result to backend for detection ID: {result['detection_id']}")
            await self.hub_client.send_message("SendClassificationResult", json.dumps(result))
        except Exception as e:
            self.logger.error(f"Error sending classification result: {e}", exc_info=True)

    async def heartbeat_worker(self):
        """Sends a periodic heartbeat to the backend."""
        while True:
            await asyncio.sleep(30)
            try:
                heartbeat_data = {
                    "service_name": "cnn_service_yolo", "status": "healthy" if self.model else "unhealthy",
                    "camera_connected": self.camera is not None and self.camera.isOpened()
                }
                await self.hub_client.send_message("SendHeartbeat", json.dumps(heartbeat_data))
            except Exception as e:
                self.logger.error(f"Error sending heartbeat: {e}")

    async def cleanup(self):
        """Cleans up resources like the camera and hub connection."""
        if self.camera:
            self.camera.release()
        await self.hub_client.disconnect()
        self.logger.info(" CNN service cleanup complete.")

    # --- PASTE THESE THREE METHODS INTO YOUR CNNService CLASS ---

    async def initialize_camera(self):
        """Initializes the camera for image capture."""
        try:
            camera_index = int(os.getenv('CAMERA_INDEX', '0'))
            self.logger.info(f"Initializing camera index {camera_index}...")
            
            self.camera = cv2.VideoCapture(camera_index)
            
            if not self.camera.isOpened(): 
                self.logger.warning("Failed to open camera, will use mock data.")
                self.camera = None
                return

            # Optional: Configure camera settings
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            
            # Warm up camera
            for _ in range(5):
                ret, _ = self.camera.read()
                if not ret: break
                    
            self.logger.info("âœ… Camera initialized successfully")
            
        except Exception as e:
            self.logger.error(f"Camera initialization failed: {e}")
            self.camera = None

    async def heartbeat_worker(self):
        """Sends a periodic heartbeat to the backend."""
        while True:
            await asyncio.sleep(30)
            try:
                heartbeat_data = {
                    "service_name": "cnn_service_yolo",
                    "status": "healthy" if self.model else "unhealthy",
                    "camera_connected": self.camera is not None and self.camera.isOpened()
                }
                await self.hub_client.send_message("SendHeartbeat", json.dumps(heartbeat_data))
            except Exception as e:
                self.logger.error(f"Error sending heartbeat: {e}")

    async def cleanup(self):
        """Cleans up resources like the camera and hub connection."""
        if self.camera:
            self.camera.release()
        await self.hub_client.disconnect()
        self.logger.info(" CNN service cleanup complete.")
    

    def get_disposal_location(self, classification: str) -> str:
        """
        Maps a final classification label to its designated disposal bin.
        """
        # This dictionary should contain all your possible FINAL classes
        disposal_map = {
            'plastic': 'Plastic Recycling Bin',
            'glass': 'Glass Recycling Bin',
            'metal': 'Metal Recycling Bin',
            'paper': 'Paper Recycling Bin',
            'cardboard': 'Cardboard Recycling Bin', # Make sure you have this if your model predicts it
            'organic': 'Organic Waste / Compost Bin',
            'unknown': 'Manual Inspection Bin',
            # Add mappings for any other WasteCategory enums you have
        }
        # .lower() makes the lookup case-insensitive and safer
        return disposal_map.get(classification.lower(), 'General Waste Bin')