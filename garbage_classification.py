# -*- coding: utf-8 -*-
"""Garbage_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M6U3t5X153ZXJncpR2lOdzchKqN1ALRF

# **This is fine-tuning the model with *Aggresive* data augmentation and with unfreeze the last block of the resnet50**
"""

import warnings
warnings.filterwarnings('ignore')

import os
import seaborn as sns
from PIL import Image

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tensorflow.keras.applications import ResNet50
from keras.models import Model
from keras.layers import Input, Activation, Add, Dense, Conv2D, GlobalAveragePooling2D, MaxPooling2D, Dropout
from tensorflow.keras.applications.resnet50 import preprocess_input

from tensorflow.keras.optimizers import Adam
from keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix



# from sklearn.utils.class_weight import compute_class_weight

# from matplotlib.colors import LinearSegmentedColormap

from keras.layers import BatchNormalization, Dropout

from tensorflow.keras.applications.resnet50 import preprocess_input

from keras.utils import plot_model

"""# Mounting preparing"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

drive_path = '/content/drive/MyDrive/AI_Trash_Sorter/datasets'
os.makedirs(drive_path, exist_ok=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd {drive_path}

!kaggle datasets download -d farzadnekouei/trash-type-image-dataset

!unzip -q /content/drive/MyDrive/AI_Trash_Sorter/datasets/trash-type-image-dataset.zip

"""**Data Checking**


"""

# Define the path where our dataset is stored
dataset_path = '/content/drive/MyDrive/AI_Trash_Sorter/datasets/TrashType_Image_Dataset'

# Retrieve the names of all folders (representing trash types) within the dataset directory
garbage_types = os.listdir(dataset_path)

# Set to store unique image dimensions for the entire dataset
all_dimensions_set = set()

# Iterate over each trash type (folder) to process images
for garbage_type in garbage_types:
    folder_path = os.path.join(dataset_path, garbage_type)

    # Verify that the current item is a directory
    if os.path.isdir(folder_path):
        image_files = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'jpeg'))]

        # Display the count of images in the current folder
        num_images = len(image_files)
        print(f"{garbage_type} folder contains {num_images} images.")

        # Loop over each image to check its dimensions
        for image_file in image_files:
            image_path = os.path.join(folder_path, image_file)
            with Image.open(image_path) as img:
                # Extract the width, height, and channels (color depth) of the image and add to the dimensions set
                width, height = img.size
                channels = len(img.getbands())
                all_dimensions_set.add((width, height, channels))

# Determine if all images in the entore dataset have the same dimensions
if len(all_dimensions_set) == 1:
    width, height, channel = all_dimensions_set.pop()
    print(f"\nAll images in the dataset have the same dimensions: {width}x{height} with {channels} color channels.")
else:
    print("\nThe images in the dataset have different dimensions or color channels.")

for garbage_type in garbage_types:
    folder_path = os.path.join(dataset_path, garbage_type)

    if os.path.isdir(folder_path):
        image_files = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'jpeg'))]

        image_files = image_files[:7]

        # Set up subplots
        fig, axs = plt.subplots(1, 7, figsize=(15, 2))

        for i, image_file in enumerate(image_files):
            image_path = os.path.join(folder_path, image_file)
            with Image.open(image_path) as img:
                axs[i].imshow(img)
                axs[i].axis('off')

        plt.tight_layout()
        fig.suptitle(garbage_type, fontsize=20, y=1.03)
        plt.show()

# Initialize an empty list to store image file paths and their respective labels
data = []

# Loop through each garbage type and collect its images' file paths
for garbage_type in garbage_types:
    for file in os.listdir(os.path.join(dataset_path, garbage_type)):
        # Append the image file path and its trash type (as a label) to the data list
        data.append((os.path.join(dataset_path, garbage_type, file), garbage_type))

# Convert the collected data into a DataFrame
df = pd.DataFrame(data, columns=['filepath', 'label'])

# Display the first few entries of the DataFrame
df.tail()

train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])

# Print the number of images in each set
print(f"Number of images in the training set: {len(train_df)}")
print(f"Number of images in the validation set: {len(val_df)}")

# 1. Class distribution in the entire dataset
overall_distribution = df['label'].value_counts(normalize=True) * 100

# 2. Class distribution in the training set
train_distribution = train_df['label'].value_counts(normalize=True) * 100

# 3. Class distribution in the validation set
val_distribution = val_df['label'].value_counts(normalize=True) * 100

print("Class distribution in the entire dataset:\n")
print(overall_distribution.round(2))
print('-'*40)

print("\nClass distribution in the training set:\n")
print(train_distribution.round(2))
print('-'*40)

print("\nClass distribution in the validation set:\n")
print(val_distribution.round(2))

# Slight Augmentation settings for training
train_datagen = ImageDataGenerator(
    rotation_range=60,                  # Randomly rotate the images by up to 60 degrees
    width_shift_range=0.15,             # Randomly shift images horizontally by up to 15% of the width
    height_shift_range=0.15,            # Randomly shift images vertically by up to 15% of the height
    zoom_range=0.20,                    # Randomly zoom in or out by up to 20%
    horizontal_flip=True,               # Randomly flip images horizontally
    vertical_flip=True,                 # Randomly flip images vertically
    shear_range=0.05,                   # Apply slight shear transformations
    brightness_range=[0.9, 1.1],        # Vary brightness between 90% to 110% of original
    channel_shift_range=10,             # Randomly shift channels (can change colors of images slightly but less aggressively)
    fill_mode='nearest',                 # Fill in missing pixels using the nearest filled value
    preprocessing_function=preprocess_input  # Add this line
)

# For the validation set, you might not have augmentation:
val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  # Add this line

# Using flow_from_dataframe to generate batches
# Generate training batches from the training dataframe
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,                  # DataFrame containing training data
    x_col="filepath",                    # Column with paths to image files
    y_col="label",                       # Column with image labels
    target_size=(384, 384),              # Resize all images to size of 384x384
    batch_size=32,                       # Number of images per batch
    class_mode='categorical',            # One-hot encode labels
    seed=42,                             # Seed for random number generator to ensure reproducibility
    shuffle=False                        # Data is not shuffled; order retained from DataFrame
)


# Generate validation batches from the validation dataframe
val_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,                    # DataFrame containing validation data
    x_col="filepath",                    # Column with paths to image files
    y_col="label",                       # Column with image labels
    target_size=(384, 384),              # Resize all images to size of 384x384
    batch_size=32,                       # Number of images per batch
    class_mode='categorical',            # One-hot encode labels
    seed=42,                             # Seed for random number generator to ensure reproducibility
    shuffle=False                        # Data is not shuffled; order retained from DataFrame
)

print(f"Number of batches in train_generator: {len(train_generator)}")
print(f"Number of batches in val_generator: {len(val_generator)}")

# Load the ResNet50 model with weights pre-trained on ImageNet
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(384, 384, 3))

base_model.summary()

len(base_model.layers)

for i, layer in enumerate(base_model.layers):
    if 140 <= i <= 175:
        print(i, layer.name)

# Freeze the layers up to conv4_block6_out
for layer in base_model.layers[:165]: # include the layer 142
    layer.trainable = False

# Create the new model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(5, activation='softmax')(x)

ft_model = Model(inputs=base_model.input, outputs=x)

# Compile the model
ft_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

ft_model.summary()

# A slightly more aggressive learning rate reducer
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)

# A slightly more aggressive early stopper
early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True, verbose=1)

"""# Training"""

# --- 2. Define Training Parameters ---
# We'll start with a reasonable number of epochs. EarlyStopping will handle the rest.
EPOCHS = 50 # A good starting point. Can be increased if needed.


# --- 3. Train the Model ---
# This is the command that starts the training process.
# Note: We do NOT include the class_weight parameter.

history = ft_model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    callbacks=[reduce_lr, early_stopping]
)

def plot_learning_curves(history, start_epoch=5):
    """
    Plot training and validation loss and accuracy curves.

    Parameters:
    - history: Training history (output from the model's fit method).
    - start_epoch: Epoch from which to start plotting. Default is 5 (i.e., plot from epoch 6 onwards).
    """

    # Convert the history.history dict to a pandas DataFrame
    df = pd.DataFrame(history.history)

    # Plot the curves from the specified epoch onwards
    df = df.iloc[start_epoch-1:]

    # Set the style of seaborn for better visualization
    sns.set(rc={'axes.facecolor': '#f0f0fc'}, style='darkgrid')

    # Plotting the learning curves
    plt.figure(figsize=(15,6))

    # Plotting the training and validation loss
    plt.subplot(1, 2, 1)
    sns.lineplot(x=df.index, y=df['loss'], color='royalblue', label='Train Loss')
    sns.lineplot(x=df.index, y=df['val_loss'], color='orangered', linestyle='--', label='Validation Loss')
    plt.title('Loss Evolution')

    # Plotting the training and validation accuracy
    plt.subplot(1, 2, 2)
    sns.lineplot(x=df.index, y=df['accuracy'], color='royalblue', label='Train Accuracy')
    sns.lineplot(x=df.index, y=df['val_accuracy'], color='orangered', linestyle='--', label='Validation Accuracy')
    plt.title('Accuracy Evolution')

    plt.show()

plot_learning_curves(history)

# --- Step 1: Get Final Loss and Accuracy ---
# This provides the single best summary of your model's performance.

print("--- Final Model Evaluation ---")
final_loss, final_accuracy = ft_model.evaluate(val_generator)
print(f"Final Validation Loss: {final_loss:.4f}")
print(f"Final Validation Accuracy: {final_accuracy:.4f}")


# --- Step 2: Get Predictions and True Labels ---
# We need these to build the detailed reports.

# Ensure the generator is at the beginning
val_generator.reset()

# Get the model's predictions
# The 'predict' function returns probabilities for each class
y_pred_probs = ft_model.predict(val_generator)

# Convert probabilities to a single predicted class index
# np.argmax finds the index (0, 1, 2, etc.) with the highest probability
y_pred = np.argmax(y_pred_probs, axis=1)

# Get the true class indices
y_true = val_generator.classes

# Get the names of the classes
class_names = list(val_generator.class_indices.keys())


# --- Step 3: Print the Classification Report ---
# This report gives a detailed breakdown of performance for each class.

print("\n--- Classification Report ---")
print(classification_report(y_true, y_pred, target_names=class_names))


# --- Step 4: Display the Confusion Matrix ---
# This matrix gives a visual breakdown of the model's mistakes.

print("\n--- Confusion Matrix ---")
confusion_mtx = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mtx,
            annot=True,      # Show the numbers in the cells
            fmt='d',         # Format the numbers as integers
            cmap='Blues',    # Use a blue color scheme
            xticklabels=class_names,
            yticklabels=class_names)

plt.ylabel('Actual (True) Label')
plt.xlabel('Predicted Label')
plt.title('Confusion Matrix')
plt.show()

model_save_path = '/content/drive/MyDrive/AI_Trash_Sorter/trash_classifier_v3_93_accuracy_4mp.h5'

ft_model.save(model_save_path)

print(f"Model successfully saved to: {model_save_path}")

model_save_path_keras = '/content/drive/MyDrive/AI_Trash_Sorter/trash_classifier_v3_93_accuracy_4mp.keras'

ft_model.save(model_save_path_keras)

print(f"Model successfully saved to: {model_save_path_keras}")

